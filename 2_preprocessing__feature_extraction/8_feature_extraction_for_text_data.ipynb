{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Feature-Extraction-for-Text-Data\" data-toc-modified-id=\"Feature-Extraction-for-Text-Data-1\">Feature Extraction for Text Data</a></span></li><li><span><a href=\"#What-about-new-words-in-the-test-set?\" data-toc-modified-id=\"What-about-new-words-in-the-test-set?-2\">What about new words in the test set?</a></span></li><li><span><a href=\"#Unseen-data-are-not-at-prediction-time\" data-toc-modified-id=\"Unseen-data-are-not-at-prediction-time-3\">Unseen data are not at prediction time</a></span></li><li><span><a href=\"#What-is-Hashing?\" data-toc-modified-id=\"What-is-Hashing?-4\">What is Hashing?</a></span></li><li><span><a href=\"#What-are-Hash-Maps?\" data-toc-modified-id=\"What-are-Hash-Maps?-5\">What are Hash Maps?</a></span></li><li><span><a href=\"#Feature-Hashing,-aka-hashing-trick\" data-toc-modified-id=\"Feature-Hashing,-aka-hashing-trick-6\">Feature Hashing, aka hashing trick</a></span></li><li><span><a href=\"#The-Advantages-of-Feature-Hashing\" data-toc-modified-id=\"The-Advantages-of-Feature-Hashing-7\">The Advantages of Feature Hashing</a></span></li><li><span><a href=\"#The-Disadvantages-of-Feature-Hashing\" data-toc-modified-id=\"The-Disadvantages-of-Feature-Hashing-8\">The Disadvantages of Feature Hashing</a></span></li><li><span><a href=\"#HashingVectorizer\" data-toc-modified-id=\"HashingVectorizer-9\">HashingVectorizer</a></span></li><li><span><a href=\"#TfidfVectorizer\" data-toc-modified-id=\"TfidfVectorizer-10\">TfidfVectorizer</a></span></li><li><span><a href=\"#Caveats\" data-toc-modified-id=\"Caveats-11\">Caveats</a></span></li><li><span><a href=\"#Bonus-Material\" data-toc-modified-id=\"Bonus-Material-12\">Bonus Material</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Feature Extraction for Text Data</h2></center>\n",
    "\n",
    "\n",
    "Text is a very rich data source. \n",
    "\n",
    "However, it can challenging to make it amenable to machine learning.\n",
    "\n",
    "We tools to build feature vectors from text documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                Type         Data/Info\n",
      "----------------------------------------------\n",
      "CountVectorizer         type         <class 'sklearn.feature_e<...>on.text.CountVectorizer'>\n",
      "ENGLISH_STOP_WORDS      frozenset    frozenset({'one', 'full',<...>ch', 'a', 'alone', 're'})\n",
      "HashingVectorizer       type         <class 'sklearn.feature_e<...>.text.HashingVectorizer'>\n",
      "TfidfTransformer        type         <class 'sklearn.feature_e<...>n.text.TfidfTransformer'>\n",
      "TfidfVectorizer         type         <class 'sklearn.feature_e<...>on.text.TfidfVectorizer'>\n",
      "strip_accents_ascii     function     <function strip_accents_ascii at 0x7f8b6bf7f550>\n",
      "strip_accents_unicode   function     <function strip_accents_u<...>nicode at 0x7f8b6bf7f3a0>\n",
      "strip_tags              function     <function strip_tags at 0x7f8b6bfe69d0>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method name | What it does |  \n",
    "|:-------|:------|\n",
    "| feature_extraction.text.CountVectorizer | Convert a collection of text documents to a matrix of token counts |\n",
    "| feature_extraction.text.HashingVectorizer | Convert a collection of text documents to a matrix of token occurrences| \n",
    "|feature_extraction.text.TfidfTransformer | Transform a count matrix to a normalized tf or tf-idf representation |\n",
    "|feature_extraction.text.TfidfVectorizer | Convert a collection of raw documents to a matrix of TF-IDF features. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BX3lrIkDuv8N"
   },
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = [\"problem of evil\",\n",
    "        \"evil king\",\n",
    "        \"horizon problem\",\n",
    "        \"king of kings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvuF4OhJvcoU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectors = CountVectorizer()\n",
    "X = count_vectors.fit_transform(text)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yAB53ZgOvzdy",
    "outputId": "e39b1192-a1be-4ee6-cbc5-477a9a39c822"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 1],\n",
       "       [1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evil', 'horizon', 'king', 'kings', 'of', 'problem']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectors.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "kReMAazWwAj5",
    "outputId": "684f226e-9b50-48b3-b893-bf57cb7d2210"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>king</th>\n",
       "      <th>kings</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  horizon  king  kings  of  problem\n",
       "0     1        0     0      0   1        1\n",
       "1     1        0     1      0   0        0\n",
       "2     0        1     0      0   0        1\n",
       "3     0        0     1      1   1        0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(X.toarray(),\n",
    "             columns=count_vectors.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>What about new words in the test set?</h2></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>king</th>\n",
       "      <th>kings</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  horizon  king  kings  of  problem\n",
       "0     0        0     0      0   0        1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = [\"queen problem\"]\n",
    "\n",
    "# Not you only call transform on test set (never call fit or fit_transform)\n",
    "X_test = count_vectors.transform(test_text)\n",
    "\n",
    "pd.DataFrame(X_test.toarray(),\n",
    "             columns=count_vectors.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Unseen data are not at prediction time</h2></center>\n",
    "\n",
    "Any new words are dropped because the model was not trained on them. This extends to categorical data and some continuous data.\n",
    "\n",
    "This is issue is frequently called \"out of distribution\". Out of distribution is one of the most difficult problems in machine learning.\n",
    "\n",
    "Remember - \"Data is the world's best regularizer.\"\n",
    "\n",
    "You want to collect as much data as possible. In particular, collect data that will look your production data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://stackoverflow.com/questions/30287371/countvectorizer-matrix-varies-with-new-test-data-for-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What is Hashing?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Converting an object into a single numeric value.</center>\n",
    "\n",
    "<center> Maps data of arbitrary sizes to data of a fixed size (often in repeatable way).</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2>What are Hash Maps?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Key-value pairs - where the key is numeric location (index) and the value is an object</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Feature Hashing, aka hashing trick</h2></center>\n",
    "<br>\n",
    "<center><img src=\"../images/feature_hashing.jpeg\" width=\"100%\"/></center>\n",
    "\n",
    "<center>Map feature values to indices in a feature vector.</center>\n",
    "\n",
    "<center>Those feature values could be <b>any</b> hashable object</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://www.quora.com/Can-you-explain-feature-hashing-in-an-easily-understandable-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# help(FeatureHasher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., -10.,   0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's feature hash \n",
    "h = FeatureHasher(n_features=10)\n",
    "\n",
    "# 1 instance & 1 feature with a value\n",
    "d = [{'dog': 10,}] \n",
    "\n",
    "# 1 instance & 1 feature with a changed value\n",
    "# d = [{'dog': 4,}] \n",
    "\n",
    "# 1 instance & 3 features\n",
    "# d = [{'dog': 10, 'cat':2, 'elephant':4}] \n",
    "\n",
    " # 2 instances\n",
    "# d = [{'dog': 10, 'cat':2, 'elephant':4},\n",
    "#      {'dog': 2, 'run': 5}] \n",
    "\n",
    "# 1 instance & many features ðŸ¤­\n",
    "# d = [{l:n for l, n in zip('abcdefghijklmnopqrstuvwxyz', range(26))}] \n",
    "    \n",
    "h.fit_transform(d).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Learn more: https://www.youtube.com/watch?v=Uv9dY6Obv-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>The Advantages of Feature Hashing</h2></center>\n",
    "\n",
    "- Fast \n",
    "- Simple\n",
    "- Memory efficient\n",
    "    - Limits feature vector size (compared to one-hot encoding)\n",
    "    - No need to store mapping feature itself (just index integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>The Disadvantages of Feature Hashing</h2></center>\n",
    "\n",
    "- Interpretability & feature importances - Cannot go from feature indices back to feature names\n",
    "- Hash collisions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>HashingVectorizer</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vector = HashingVectorizer()\n",
    "X = hash_vector.fit_transform(text)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        , -0.57735027,  0.57735027,  0.57735027,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.70710678,  0.70710678,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.70710678,  0.        , -0.70710678,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_vector = HashingVectorizer(n_features=7)\n",
    "X = hash_vector.transform(text) #  HashingVectorizer is stateless, meaning that you donâ€™t have to call fit on it:\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HashingVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-01535a368221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhash_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Hashing in this case is a way operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HashingVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "hash_vector.get_feature_names()\n",
    "\n",
    "# Hashing in this case is a way operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a couple of cons (vs using a CountVectorizer with an in-memory vocabulary):\n",
    "\n",
    "- there is no way to compute the inverse transform (from feature indices to string feature names) which can be a problem when trying to introspect which features are most important to a model.\n",
    "\n",
    "- there can be collisions: distinct tokens can be mapped to the same feature index. However in practice this is rarely an issue if n_features is large enough (e.g. 2 ** 18 for text classification problems).\n",
    "\n",
    "- no IDF weighting as this would render the transformer stateful.\n",
    "\n",
    "[Source](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tz_6mQa-wUGZ"
   },
   "source": [
    "<center><h2>TfidfVectorizer</h2></center>\n",
    "\n",
    "TF-IDF was covered in a previous course (MSDS 621). Reference those notes [here](https://github.com/parrt/msds692/blob/9a7ded161fe37eacd6d3b21533aebd9d7e148ef1/notes/tfidf.ipynb) and [here](https://github.com/parrt/msds692/blob/6ec05ef972ec94e185645f407002956d63111a86/hw/tfidf.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Caveats</h2></center>\n",
    "\n",
    "- scikit-learn is not designed for rich text processing and modeling. It does a couple of things.\n",
    "- I suggest using spaCy for more options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Bonus Material</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should I choose n features in featurehasher?\n",
    "\n",
    "- Default is good enough.\n",
    "- Otherwise a power of 2 is a good idea.\n",
    "\n",
    "[Source](https://datascience.stackexchange.com/questions/77819/how-should-i-choose-n-features-in-featurehasher-in-sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Webinar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
